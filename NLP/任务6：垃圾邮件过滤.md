[TOC]
# 任务6：垃圾邮件过滤

## 1 任务目标

1. 掌握数据清洗和数据预处理
2. 熟练掌握贝叶斯定理
3. 学习编写朴素贝叶斯分类器应用




## 2 任务描述

- 在我们日常生活中，经常会受到各种垃圾邮件，譬如来自商家的广告、打折促销信息、澳门博彩邮件、理财推广信息等，一般来说邮件客户端都会设置一定的关键词屏蔽这种垃圾邮件，或者对邮件进行归类，但是总会有一些漏网之鱼。不过，自己手动做一个垃圾邮件分类器也并不是什么难事。传统的机器学习算法通常会采用朴素贝叶斯、支持向量机等算法对垃圾邮件进行过滤，今天我们主要讲如何用Python手写一个朴素贝叶斯垃圾邮件分类器。


## 3 知识准备


### 3.1 贝叶斯原理
在上一章的任务中，我们已经知道贝叶斯原理是怎么一回事，还记得怎么求算不同的条件概率吗？
在本章的问题中，我们需要实现的是分类。基于概率论，二分类问题的解决方案如下： 
- 如果p1 > p2, 分入类别1； 否则分入类别2。
其次，在贝叶斯定理中，有

```math
P(C_i|x,y) = \frac{P(x,y|C_i)P(C_i)}{P(x,y)}
```
其中，x,y表示特征变量，
```math
C_i
```
表示类别。
而

```math
P(C_i|x,y)
```
表示在特征x,y出现的情况下，分入类别
```math
C_i
```
的概率。即如果

```math
P(C_i|x,y)>P(C_j|x,y)
```
分入类别i， 否则分入类别j。


### 3.2 了解数据集
今天我们用的数据集如下：

```
data
│
└───normal //正常邮件示例
│   │   201
│   │   202
│   │   ...
│   └───2077
└───spam // 垃圾邮件示例
│   │   1
│   │   10
│   │   ...
│   └───1907
└───test //测试集
│   │   1
│   │   ...
│   └───8000
```

垃圾邮件spam示例：
> 你好：
    以茶会友，以茶联谊，喝茶就喝安溪铁观音http://www.xxdd88.com/
本厂是专业生产批发各等级铁观音茶叶的，购买联系：13960226828
在线QQ:315256（可以留言）
    安溪感德铁观音（有图）http://www.xxdd88.com/sanye/铁观音茶叶.jpg




                                       福建安溪感德三叶茶厂
                                          2005.07.03
                                          
正常邮件normal示例：
> 项目管理者联盟招聘内容编辑一名，欢迎大家帮忙推荐。
工作地点：北京市德胜门外 
学    历：大专以上 
工作年限：一年以上 
内容编辑的工作内容如下：
1. 负责项目管理者联盟网站[http://www.mypm.net]内容的收集、整理、编辑。
2. 配合内容总编，进行网站栏目的规划和更新、活动组织等工作。
职位的基本要求如下：
1. 具有较强的文字功底、良好的语言表达和沟通能力
2. 熟悉网络操作和office软件操作
3. 为人踏实肯干，男女不限
4. 有网站内容编辑工作经验者优先
5. 对项目管理知识有一定了解者优先
欢迎大家推荐人员应聘。
应聘者请将简历发送邮件至：yhua@mypm.net
并请在简历中注明待遇要求。

### 3.3 数据预处理
拿到数据后我们可以很清楚的看到邮件的内容。如果仔细观察的话，会发现不是所有的邮件都能直接打开，数据的编码格式也需要转换成utf-8格式方便我们后面训练使用。所以我们在实际任务处理过程中需要对原始数据做一些数据预处理，包括以下几个内容。

- 转换源数据编码格式为utf-8格式
- 转换过滤字符
- 转换过滤停用词
- 转换对邮件内容进行分词处理


## 4 任务实施

### 4.1 实施思路
基于贝叶斯推断的垃圾邮件过滤器。通过8000封正常邮件和8000封垃圾邮件“训练”过滤器: 解析所有邮件，提取每一个词,然后，计算每个词语在正常邮件和垃圾邮件中的出现频率。

1. 当收到一封未知邮件时，在不知道的前提下，我们假定它是垃圾邮件和正常邮件的概率各 为50%：

```math
p(s) = p(n) = 0.5
```
2. 解析该邮件，提取每个词，计算该词的p(s|w)，也就是受该词影响，该邮件是垃圾邮件的概率：

```math
p(s|w)
```
3. 提取该邮件中p(s|w)最高的15个词，计算联合概率：

```math
 		
 p = \frac{	p(s|w1)p(s|w2)...p(s|w15)}{p(s|w1)p(s|w2)...p(s|w15) + (1-p(s|w1))(1-p(s|w2)...(1-p(s|w15)))}
 	
```
4. 设定分类阈值:
p > 0.9 :垃圾邮件
p < 0.9 :正常邮件

5. 注:如果新收到的邮件中有的词在史料库中还没出现过，就假定p(s|w) = 0.4



### 4.2 实施步骤


#### 步骤1：定义基本变量

```
import re
# spam类对象
spam=spamEmailBayes()
# 保存词频的词典
spamDict={}
normDict={}
testDict={}
# 保存每封邮件中出现的词
wordsList=[]
wordsDict={}
# 保存预测结果,key为文件名，值为预测类别
testResult={}
# 分别获得正常邮件、垃圾邮件及测试文件名称列表
normFileList=spam.get_File_List(r"C:\Users\15845\data\normal")
spamFileList=spam.get_File_List(r"C:\Users\15845\data\spam")
testFileList=spam.get_File_List(r"C:\Users\15845\data\test")
# 获取训练集中正常邮件与垃圾邮件的数量
normFilelen=len(normFileList)
spamFilelen=len(spamFileList)
# 获得停用词表，用于对停用词过滤
stopList=spam.getStopWords()
```


#### 步骤2：数据预处理
用结巴分词，并用停用表进行简单过滤，然后使用正则表达式过滤掉邮件中的非中文字符；

```
class spamEmailBayes:
    # 获得停用词表
    def getStopWords(self):
        stopList = []
        for line in open ( r"..\stopWord.txt" ):
            stopList.append ( line[:len ( line ) - 1] )
        return stopList;

    # 获得词典
    def get_word_list(self, content, wordsList, stopList):
        # 分词结果放入res_list
        res_list = list ( jieba.cut ( content ) )
        for i in res_list:
            if i not in stopList and i.strip () != '' and i != None:
                if i not in wordsList:
                    wordsList.append ( i )

    # 若列表中的词已在词典中，则加1，否则添加进去
    def addToDict(self, wordsList, wordsDict):
        for item in wordsList:
            if item in wordsDict.keys ():
                wordsDict[item] += 1
            else:
                wordsDict.setdefault ( item, 1 )

    def get_File_List(self, filePath):
        filenames = os.listdir ( filePath )
        return filenames
        
# 获得正常邮件中的词频
for fileName in normFileList:
    wordsList.clear()
    for line in open(r"..\data\normal\\"+fileName):
        #过滤掉非中文字符
        rule=re.compile(r"[^\u4e00-\u9fa5]")
        line=rule.sub("",line)
        #将每封邮件出现的词保存在wordsList中
        spam.get_word_list(line,wordsList,stopList)
    #统计每个词在所有邮件中出现的次数
    spam.addToDict(wordsList, wordsDict)
normDict=wordsDict.copy()  

#获得垃圾邮件中的词频
wordsDict.clear()
for fileName in spamFileList:
    wordsList.clear()
    for line in open(r"..\data\spam\\"+fileName):
        rule=re.compile(r"[^\u4e00-\u9fa5]")
        line=rule.sub("",line)
        spam.get_word_list(line,wordsList,stopList)
    spam.addToDict(wordsList, wordsDict)
spamDict=wordsDict.copy()
```

#### 步骤3：计算贝叶斯概率

```
class spamEmailBayes:
    # 通过计算每个文件中p(s|w)来得到对分类影响最大的15个词
    def getTestWords(self, testDict, spamDict, normDict, normFilelen, spamFilelen):
        wordProbList = {}
        for word, num in testDict.items ():
            if word in spamDict.keys () and word in normDict.keys ():
                # 该文件中包含词个数
                pw_s = spamDict[word] / spamFilelen
                pw_n = normDict[word] / normFilelen
                ps_w = pw_s / (pw_s + pw_n)
                wordProbList.setdefault ( word, ps_w )
            if word in spamDict.keys () and word not in normDict.keys ():
                pw_s = spamDict[word] / spamFilelen
                pw_n = 0.01
                ps_w = pw_s / (pw_s + pw_n)
                wordProbList.setdefault ( word, ps_w )
            if word not in spamDict.keys () and word in normDict.keys ():
                pw_s = 0.01
                pw_n = normDict[word] / normFilelen
                ps_w = pw_s / (pw_s + pw_n)
                wordProbList.setdefault ( word, ps_w )
            if word not in spamDict.keys () and word not in normDict.keys ():
                # 若该词不在脏词词典中，概率设为0.4
                wordProbList.setdefault ( word, 0.4 )
        sorted ( wordProbList.items (), key=lambda d: d[1], reverse=True )[0:15]
        return (wordProbList)

    # 计算贝叶斯概率
    def calBayes(self, wordList, spamdict, normdict):
        ps_w = 1
        ps_n = 1

        for word, prob in wordList.items ():
            print ( word + "出现的概率为" + str ( prob ) )
            ps_w *= (prob)
            ps_n *= (1 - prob)
        p = ps_w / (ps_w + ps_n)
        #         print(str(ps_w)+"////"+str(ps_n))
        return p
```
可以看得到不同词出现的频率分别为：

![image](https://s2.ax1x.com/2019/10/15/KPiTAA.png)
#### 步骤4：测试邮件
我们的测试集中文件名低于1000的为正常邮件：

```
# 测试邮件
for fileName in testFileList:
    testDict.clear( )
    wordsDict.clear()
    wordsList.clear()
    for line in open(r"..\data\test\\"+fileName):
        rule=re.compile(r"[^\u4e00-\u9fa5]")
        line=rule.sub("",line)
        spam.get_word_list(line,wordsList,stopList)
    spam.addToDict(wordsList, wordsDict)
    testDict=wordsDict.copy()
    #通过计算每个文件中p(s|w)来得到对分类影响最大的15个词
    wordProbList=spam.getTestWords(testDict, spamDict,normDict,normFilelen,spamFilelen)
    #对每封邮件得到的15个词计算贝叶斯概率  
    p=spam.calBayes(wordProbList, spamDict, normDict)
    if(p>0.9):
        testResult.setdefault(fileName,1) # 判断为垃圾邮件
    else:
        testResult.setdefault(fileName,0)

#计算分类准确率（测试集中文件名低于1000的为正常邮件）
testAccuracy=spam.calAccuracy(testResult)
for i,ic in testResult.items():
    if ic == 1:
        print("第"  + i+"封是垃圾邮件。")
    else:
        print("第"  + i+"封不是垃圾邮件。")
print("准确率： ",testAccuracy)
```
分类器的准确率如下：

![image](https://s2.ax1x.com/2019/10/15/KPFkcT.png)




## 5 任务拓展
贝叶斯估计/多项式模型

用极大似然估计可能会出现所要估计的概率值为0的情况，这会影响到后验概率的计算，使分类产生偏差。解决这个问题的办法是使用贝叶斯估计，也被称为多项式模型。

当特征是离散的时候，使用多项式模型。多项式模型在计算先验概率

```math
P(y_k)
```
和条件概率

```math
P(x_i|y_k)
```
的时候，会做一些平滑处理。

```math
P(y_k)=\frac{N_yk+\alpha}{N+\alpha}
```
其中，N是总的样本个数，k是总的类别个数，
```math
N_yk
```
是类别为yk的样本个数，α是平滑值。

```math
P(x_i|y_k)=\frac{N_{yixi}+\alpha}{N_{yk}+n\alpha}
```
其中，
```math
N_{yk}
```
是类别为yk的样本个数，n是特征的维数，

```math
N_{yk},x_i
```
是类别为yk的样本中，第i维特征的值是

```math
x_i
```
的样本个数，α是平滑值。
当α=1时，称作Laplace平滑，当0<α<1时，称作Lidstone平滑，α=0时不做平滑。
如果不做平滑，当某一维特征的值xi没在训练样本中出现过时，会导致
```math
P(x_i|y_k)=0
```
，从而导致后验概率为0。加上平滑就可以克服这个问题。



## 6 任务实训


### 6.1 实训目的
1. 掌握数据预处理的方法
2. 掌握通过朴素贝叶斯实现垃圾邮件分类
3. 掌握基本的文件处理方法

### 6.2 实训内容
除了本章给出的数据集以外，更常用的数据集之一是[trec06](https://plg.uwaterloo.ca/~gvcormac/treccorpus06/)c是一个公开的垃圾邮件语料库，由国际文本检索会议提供，分为英文数据集（trec06p）和中文数据集（trec06c），其中所含的邮件均来源于真实邮件保留了邮件的原有格式和内容。

试着用这个数据集去实现你自己的邮件过滤器吧！


