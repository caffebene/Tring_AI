[TOC]
# 任务1：走进自然语言处理

## 1 任务目标

1. 了解自然语言处理的发展

2. 了解现代汉语的特点及nlp的难度

3. 了解nlp技术环节及常用算法


## 2 任务描述

中文有一句著名的无标点符号的句子：下雨天留客天留我不留。对于这句话，你有什么解读呢？
基本拆解可以拆解成为以下两种意思：

- 下雨天留客，天留我不留
- 下雨天，留客天，留我不？留

但是就是这截然不同的两种解读方式，在客人留给主人家的字条中被主人误读，于是主人送客，令客人无栖身之地。

除此以外还有：
- 来到杨过曾经生活过的地方，小龙女动情地说：“我也想过过过儿过过的生活。”
- 来到儿子等校车的地方，邓超对孙俪说：“我也想等等等等等过的那辆车。”
- 赵敏说：我也想控忌忌己不想无忌。
- 你也想犯范范范玮琪犯过的错吗
- 。。。

上述不同的例子对外国人来说相当于是中文八级分词难度的句子，应该如何交给计算机去处理呢？
这就谈到了我们的自然语言处理技术。


## 3 知识准备

### 3.1自然语言处理
#### 3.1.1 什么是自然语言处理
- 自然语言处理（英语：Natural Language Processing，缩写作 NLP）是人工智能和语言学领域的分支学科。此领域探讨如何处理及运用自然语言；自然语言处理包括多方面和步骤，基本有认知、理解、生成等部分。
- 自然语言认知和理解是让计算机把输入的语言变成有意思的符号和关系，然后根据目的再处理。由于理解（understanding）自然语言，需要关于外在世界的广泛知识以及运用操作这些知识的能力，自然语言认知，同时也被视为一个人工智能完备（AI-complete）的问题。同时，在自然语言处理中，"理解"的定义也变成一个主要的问题。
- 自然语言生成系统则是把计算机数据转化为自然语言。

#### 3.1.2 自然语言处理的主要范畴

NLP 的机制涉及两个流程：
1. 自然语言理解
2. 自然语言生成


NLP的主要应用范畴如下：
- 文本朗读（Text to speech）/语音合成（Speech synthesis）
- 语音识别（Speech recognition）
- 中文自动分词（Chinese word egmentation）
- 词性标注（Part-of-speech tagging）
- 句法分析（Parsing）
- 自然语言生成（Natural language generation）
- 文本分类（Text categorization）
- 信息检索（Information retrieval）
- 信息抽取（Information extraction）
- 文字校对（Text-proofing）
- 问答系统（Question answering）
给一句人类语言的问句，决定其答案。 典型问题有特定答案 (像是加拿大的首都叫什么?)，但也考虑些开放式问句(像是人生的意义是是什么?)
- 机器翻译（Machine translation）
将某种人类语言自动翻译至另一种语言
- 自动摘要（Automatic summarization）
产生一段文字的大意，通常用于提供已知领域的文章摘要，例如产生报纸上某篇文章之摘要
- 文字蕴涵（Textual entailment）
两个文本片段有指向关系时，当认为一个文本片段真实时，可以推断出另一个文本片段的真实性。
- 命名实体识别（Named entity recognition）
识别文本中具有特定意义的实体。
- ...


#### 3.1.3 要求的学科基础
自然语言处理是一门交叉学科，要学好自然语言处理还需要有以下学科基础：

![image](https://s2.ax1x.com/2019/10/13/uv0Maq.png)

### 3.2 自然语言处理的发展

![image](https://s2.ax1x.com/2019/10/15/KPkSKO.png)

#### 3.2.1 基于规则的自然语言处理
在20世纪60年代，科学家对nlp的普遍认识是分析语义和获取语义。 这是因为受到了传统语言研究的影响—学习语言要学习语法规则、词性和构词。

这些规则是人类学习语言的好工具，而这些规则又很容易用计算机描述，所以坚定了大家对基于规则的nlp的信心。

看一个例子：徐志摩喜欢林徽因。这个句子可以分为主语、动词短语和句号三部分，然后对每个部分进一步分析。

但是随着文法规则的增加，语言学家几乎已经来不及写了，而且这些规则到后来甚至会出现矛盾，为了解决矛盾，还要说明各个规则的使用环境。

nlp在演变过程中，产生了词义和上下文相关的特性。因此，它的文法是比较复杂的上下文有关文法。复杂的算法需要更加大的计算量以及耗时更长，所以，在20世纪70年代，即便是IBM这样的大公司，也不可能采用规则的方法分析一些真实的语句。

#### 3.2.2 基于统计的自然语言处理
统计语言模型是自然语言处理的基础，它是一种具有一定上下文相关特性的数学模型，本质上也是概率图模型的一种，并且广泛应用于机器翻译、语音识别、拼音输入、图像文字识别、拼写纠错、查找错别字和搜索引擎等。在很多任务中，计算机需要知道一个文字序列是否能构成一个大家理解、无错别字且有意义的句子，比如这句话：
> 许多人可能不太清楚到底机器学习是什么，而它事实上已经成为我们日常生活中不可或缺的重要组成部分。

这一句话很通顺，意思也很清楚，人们很容易就知道这句话在说什么。如果我们改变一些顺序，或者替换一些词：

> 不太清楚许多人可能机器学习是什么到底，而它成为已经日常我们生活中组成部分不可或缺的重要。

虽然语句不通顺，看起来有些费劲，但是还能大致理解是什么意思。但是如果这样呢：

> 不清太多人机可楚器学许能习是么到什底，而已常我它成经日为们组生中成活部不重可的或缺分要。

这基本上就是无解了，根本不知所云。

至于为什么句子会是这样，语言学家可能会说，第一个句子符合语法规范，词义清楚，第二个句子词义尚且还清楚，第三个连词义都模模糊糊了。这正是从基于规则角度去理解的，在上个世纪70年代以前，科学家们也是这样想的。而之后，贾里尼克使用了一个简单的统计模型就解决了这个问题。从统计角度来看，第一个句子的概率很大，比如是10^-30，而第二个其次，比如是10^-50，第三个呢，最小，比如是10^-120。按照这种模型，第一个句子出现的概率是第二个的10的20次方倍，更不用说第三个句子了，不是第一个句子才怪。

#### 3.2.3 自然语言处理与深度学习
近年来，深度学习（DL）架构和算法在图像识别、语音处理等领域实现了很大的进展。

而深度学习在自然语言处理方面的表现最初并没有那么起眼，不过现在我们可以看到深度学习对 NLP 的贡献，在很多常见的 NLP 任务中取得了顶尖的结果，如命名实体识别（NER）、词性标注（POS tagging）或情感分析，在这些任务中神经网络模型优于传统方法。而机器翻译的进步或许是最显著的。

那么为什么深度学习技术能给NLP领域带来进步呢？我们现在来了解一下：

首先什么是深度学习？
- 深度学习（英语：deep learning）是机器学习的分支，是一种以人工神经网络为架构，对数据进行表征学习的算法。

- 深度学习的概念源于人工神经网络的研究，含多个隐藏层的多层感知器就是一种深度学习结构。深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。研究深度学习的动机在于建立模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像，声音和文本等。

然后我们为什么需要深度学习？
- 对机器学习来说，特征提取并不简单。特征工程往往需要大量的时间去优化，而此时，深度学习便可以自动学习特征和任务之间的关联，还能从简单特征中提取复杂的特征。深度学习的概念源于人工神经网络的研究，含多隐层的多层感知器就是一种深度学习结构，深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。


![image](https://s2.ax1x.com/2019/10/16/Ki2lOH.md.png)

如上图所示，在深度学习的方法中，我们可以把数据(Data)分成训练集(Train set)和测试集(Test set)，通过深度学习算法(Learning Algorithm)可以得出数据的不同特征(Feature)，从而对我们的测试集数据进行预测(Prediction/Classifier)，预测结果的正误会反馈给算法，不断修正我们的算法模型。

从根本上说，深度学习在 NLP 问题上的优势有三，这是传统机器学习方法所不具备的。

1. 表达能力：利用深度学习，文本、图像等不同格式都可以表示为实值向量，这使得我们可以跨多种模式执行信息处理。例如，在图像检索中将查询（文本）与图像进行匹配并找到最相关图像变得可行，因为它们都可以表示为向量。

2. 可训练性：深度学习让我们可以为应用执行端到端的训练，从而快速、高质量地解决问题，因为深度神经网络使得数据中的信息能在模型中被有效“编码”。例如，在神经机器翻译（NMT）中，模型完全由平行数据集（parallel corpora）自动构建，通常不需要人为干预。与统计机器翻译的传统方法相比，这显然是一个优势，特征工程对于后者是至关重要的。

3. 可推广性：机器对未经训练的数据也可以执行预测。

深度学习应用在自然语言处理：
优势：
- 擅长模式识别问题
- 数据驱动，且在很多问题上性能都很高
- 端到端训练，构建系统时很少需要或不需要领域知识（当然这一点也有争议）
- 表示学习，使得跨模式处理可行
- 基于梯度的学习，学习算法很简单
- 主要是监督学习方法

挑战：
- 不擅长推理和决策
- 不能直接处理符号
- 数据饥渴，在数据量较小时不适用
- 难以处理长尾现象
- 模型通常是一个黑盒子，可解释性差
- 计算成本很高
- 无监督学习方法有待突破
- 仍然缺乏理论基础


### 3.3 自然语言处理中的语料库
#### 3.3.1 什么是语料库
- 像多数深度学习和其他类型的机器学习的任务一样，自然语言处理也需要优质的定型数据集才能正常运作。
- 定型数据集是大量已知数据的集合，它的收集和建立需要时间，也需要特定领域的专业知识——要懂得从何处、以何种方式来收集有意义的信息。
- 定型数据集在深度学习网络的定型过程中起到基准的作用。

![image](https://s2.ax1x.com/2019/10/15/KPkAPI.png)
- 在自然语言处理学科中，这样的定型数据集我们称之为语料库。
- 语料库（corpus）一词在语言学上意指大量的文本，是在语言的实际使用中真实出现过的语言材料，通常经过整理，具有既定格式与标记。
- 事实上，语料库英文 "text corpus" 的涵意即为 "body of text"。
语料库是语料库语言学研究的基础资源，也是经验主义语言研究方法的主要资源。
- 语料库就如同一颗颗洋葱，若要获得最小单位的字词，需要由外而内一层多层剥开。自然语言处理流程就恰好把洋葱剥皮，剥的顺序以及方法不一样，剥的顺序以及方法不一样，产生的字词就不一样。
- 从语料库到文本的过程，如下所示：

![image](https://s2.ax1x.com/2019/10/13/uvB3TI.png)

#### 3.3.2 如何获取语料库
##### 3.3.2.1 英文语料库的获取
NLTK是由宾夕法尼亚大学计算机和信息科学使用python语言实现的一种自然语言工具包，其中收集了大量公开数据集。比如NLTK的nltk_data就囊括数个在 NLP 研究圈里广泛使用的实用语料库，针对英文的自然语言处理，已经成果显著，资源也易于获取。
列出NLTK里的语料库如下：
- 布朗语料库（Brown Corpus）：第一个可以在计算语言学处理中使用的通用英语语料库。它包含了一百万字 1961 年出版的美语文本。它代表了通用英语的样本，采样自小说，新闻和宗教文本。随后，在大量的人工标注后，诞生了词性标注过的版本。
- 古登堡语料库（Gutenberg Corpus）：古登堡计划（Gutenberg Project）致力于将文化作品的数字化和归档，并鼓励创作和发行电子书。古登堡语料库选择了 14 个文本，整个语料库包含了一百七十万字。
- Stopwords Corpus：NLTK 所收集的停用词语料库（Stopwords Corpus）包含了 来自 11 种不同语言（包括英语）的 2400 个停用词

除此之外还有其他的著名英文语料库：[美国当代英语语料库](http://corpus.byu.edu/coca/)、[柯林斯英语语料库](http://www.collinslanguage.com/)、[英国国家语料库](http://sara.natcorp.ox.ac.uk/)...

##### 3.3.2.2 中文语料库
- [搜狗20061127新闻语料(包含分类)](https://pan.baidu.com/s/1bnhXX6Z)
- [分词库(语料)：包含非常多的各行业词汇](https://pan.baidu.com/s/1gdJJ1FP)
- [中国自然语言开源组织(nlpcn)语料资源](http://www.nlpcn.org/resource/list/2)
- [国家语委现代汉语语料库](http://www.cncorpus.org/Resources.aspx/)，现代汉语语料库在线提供免费检索的语料约2000万字，为分词和词性标注语料。
- [古代汉语语料库](http://www.cncorpus.org/ACindex.aspx)：提供了分词、词性标注软件、词频统计、字频统计软件
- ...

##### 3.3.2.3 Github资源
- [weixin_public_corpus](https://github.com/nonamestreet/weixin_public_corpus)：微信公众号语料库，目前数据大约3G
- [CEC-Corpus](https://github.com/shijiebei2009/CEC-Corpus)：中文突发事件语料库
- [chinese-corpus](https://github.com/ml-distribution/chinese-corpus)：中文相关词典和语料库


### 3.4 现代汉语的特点
既然谈到了中文语料库，相对于我们从小就开始学习的有语法句法的英文来说，我们的母语汉语有什么特点呢？

![image](https://s2.ax1x.com/2019/10/15/KPkDiR.png)
相对于英语nlp，汉语nlp到底难在哪里？
我们看一下此类与句子成分的对应关系就能一目了然：

![image](https://s2.ax1x.com/2019/10/15/KPkjoj.md.png)

nlp落地需要语言和计算并举，上文我们只是讨论了语言，在后面的章节中我们会慢慢探讨如何通过计算机计算去处理不同的语言文本。
## 4 任务实施
NLP的研究对象是语言，不能脱离语言谈NLP，而是必须基于语言知识，同时利用计算机技术来进行NLP的处理。在本任务中，我们就先代替计算机来对语言进行处理吧。

#### 任务一
- 还记得前文中提到的下雨天留客天留我不留吗？你能想到几种巧妙的拆解方式呢？

### 4.1 实施思路
标点符号是语言的一部分，且各司其职。然而，这些立大功的小兵，却容易被人忽略、错用；加上资讯爆炸时代的来临，导致语言习惯演变为方便导向，让人更容易忽略标点符号的重要性：尤其是与我们关系最紧密的「逗号」。那么我们该怎么给这句话加上不同位置的逗号呢？

### 4.2 实施方法

1. 下雨天留客，天留我不留。 (下雨天时留住客人，但主人自白心声，天虽要留人，我不愿留客人。）

2. 下雨天留客，天留我？不留。 （下雨天时留住客人，客人自问天意要留住自己吗？客人的决定是不留。）

3. 下雨天留客，天留我不？留。 （下雨天时留住客人，客人自问自答，老天爷是否要我留？客人自答：对，正是要我留下。）

4. 下雨，天留客；天留我不留？ （此时天雨，老天爷在留客人，客人自己在犹豫着老天爷的真意为何?）

5. 下雨天，留客天，留我？不留。 （下雨天，正是留住客人的时候，不论天意留我或主人留我，我就是坚决不留。）

6. 下雨天，留客天；留我不？留。 （下雨天，正是个留客的日子。客人问「主人不肯留我是吗？」客人偏要留下。）

7. 下雨天，留客天，留我不留？ （下雨天，正是个留客的日子。客人自己问自己，主人是否会慰留我？）


## 5 任务拓展
推荐阅读书目：
1. 《人工智能》（李开复）
2. 《数学之美》（吴军）
3. 《概率论与数理统计》（盛骤等）
4. 《NLP汉语自然语言处理》（郑捷）
5. 《自然语言处理综论》（冯志伟、孙乐）

## 6 任务实训


### 6.1 实训目的
- 深刻理解句子含义的多变性

### 6.2 实训内容
对**兄弟情聚会情聚咱不聚**这句话，你能想到哪几种解读方式呢？

### 6.3 实训答案
- 兄弟情聚会，情聚咱不聚。
- 兄弟情聚会，情聚，咱不聚。
- 兄弟情聚会，情聚咱？不聚。
- 兄弟情聚会，情聚咱不？聚。
- 兄弟，情聚会，情聚咱不聚。
- 兄弟情，聚会情，聚咱？不聚。
- 兄弟情，聚会情，聚咱不？聚。
- 兄弟情，聚会情，聚咱不聚？
