[TOC]

# 任务2：图像增广

## 1.任务目标

<!-- 1. 
2. 
3. 
4.  -->

- 了解图像增强的方法
- 能够通过传统的算法增强图像
- 学习利用深度学习的方法增强图像


## 2.任务描述


- 在过去的几年中，紧凑型相机传感器的质量有了显着提高，这使移动摄影达到了新的水平。由于采用了先进的后处理软件和硬件工具，即使是低端设备也能在适当的照明条件下拍摄出相当不错的照片。但是，就艺术质量而言，移动设备仍落后于其数码单反相机。较大的传感器和高光圈光学元件可提供更好的照片分辨率，色彩再现和更低的噪点，而它们的附加传感器有助于微调拍摄参数。这些物理差异会导致严重的障碍，使得紧凑型移动设备无法达到DSLR相机的质量。
- 尽管存在许多用于自动图像增强的摄影师工具，但它们通常只专注于调整全局参数（例如对比度或亮度），而不会提高纹理质量或不考虑图像语义。除此之外，它们通常基于一组预定义的规则，这些规则并不总是考虑特定设备的细节。因此，照片后期处理的主要方法仍然基于使用专用润饰软件的手动图像校正。



## 3.知识准备


### 3.1图像模糊产生的原因

- （1）相机抖动，拍摄时相机不稳，全部画面被模糊。
- （2）物体的运动，部分物体运动，不同区域模糊不同。
- （3） 镜头失焦，大光圈小景深时的效果，等等。


### 3.2基于直方图均衡化的图像增强


- 直方图均衡化是通过调整图像的灰阶分布，使得在0~255灰阶上的分布更加均衡，提高了图像的对比度，达到改善图像主观视觉效果的目的。对比度较低的图像适合使用直方图均衡化方法来增强图像细节。


### 3.3基于拉普拉斯算子的图像增强


- 使用中心为5的8邻域拉普拉斯算子与图像卷积可以达到锐化增强图像的目的，拉普拉斯算子如下图所示：

$$
 \begin{matrix}
   0 & -1& 0 \\
   -0 & 5& -1 \\
   0 & -1& 0 
  \end{matrix} 
$$
- 拉普拉斯算子可以增强局部的图像对比度。

### 3.4基于对数Log变换的图像增强


- 对数变换可以将图像的低灰度值部分扩展，显示出低灰度部分更多的细节，将其高灰度值部分压缩，减少高灰度值部分的细节，从而达到强调图像低灰度部分的目的。变换方法：

<!-- <div align=center>
    <img src="./img/ch5/1.jpg" width="300"/>
</div> -->

$$s=c\cdot log_{v+1}{(1+v\cdot r)} \qquad r\in [0,1]$$




- 对数变换对图像低灰度部分细节增强的功能过可以从对数图上直观理解：
<div align=center>
    <!-- ![应用场景](./img/16cv应用场景.jpg) -->
    <img src="./img/ch5/2.jpg" width="300"/>
</div>


- x轴的0.4大约对应了y轴的0.8，即原图上0~0.4的低灰度部分经过对数运算后扩展到0~0.8的部分，而整个0.4~1的高灰度部分被投影到只有0.8~1的区间，这样就达到了扩展和增强低灰度部分，压缩高灰度部分的值的功能。
- 从上图还可以看到，对于不同的底数，底数越大，对低灰度部分的扩展就越强，对高灰度部分的压缩也就越强。


### 3.5基于伽马变换的图像增强

- 伽马变换主要用于图像的校正，将灰度过高或者灰度过低的图片进行修正，增强对比度。变换公式就是对原图像上每一个像素值做乘积运算：

<!-- <div align=center>
    <img src="./img/ch5/3.jpg" width="300"/>
</div> -->

$$s=cr^\gamma \qquad \gamma \in [0,1]$$

- 伽马变换对图像的修正作用其实就是通过增强低灰度或高灰度的细节实现的，从伽马曲线可以直观理解：

<div align=center>
    <!-- ![应用场景](./img/16cv应用场景.jpg) -->
    <img src="./img/ch5/4.jpg" width="300"/>
</div>

- γ值以1为分界，值越小，对图像低灰度部分的扩展作用就越强，值越大，对图像高灰度部分的扩展作用就越强，通过不同的γ值，就可以达到增强低灰度或高灰度部分细节的作用。
- 伽马变换对于图像对比度偏低，并且整体亮度值偏高（对于于相机过曝）情况下的图像增强效果明显。



### 3.6 基于卷积神经网络的图像增强

- 基于深度学习的方法和传统的优化的方法都提出了对于图像的非均匀模糊问题进行了解决，但对于动态场景的模糊问题，也就是图像中只有局部区域存在模糊的问题难以解决。2017年，Seungjun等人总结现有的图像去模糊算法中存在的问题为：

1. 难以获得实测清晰图像和模糊图像对用于训练图像去模糊网络；
2. 对于动态场景的图像去模糊问题，难以获得局部图像的模糊核；
3. 去模糊问题需要较大的感受野。
- 针对上述提出的问题，作者提出了一种实测动态场景图像合成的方式，并公开了用于动态场景的图像去模糊数据集gopro_large， gopro数据集已经成为目前基于深度学习的去模糊算法最常用的数据集之一 。而针对难以获得动态场景的局部区域的模糊核问题，作者选择一种基于深度学习的端到端的图像去模糊的算法，抛弃了传统的方法先估计模糊核在估计清晰图像的策略，使用卷积神经网络从退化图像中直接复原清晰图像。并且仿照 传统的图像去模糊问题中多尺度的复原策略融入到网络中，网络设计如下图所示。

<div align=center>
    <!-- ![应用场景](./img/16cv应用场景.jpg) -->
    <img src="./img/ch5/5.jpg" width="700"/>
</div>

- 作者通过三个多尺度的卷积神经网络，其中B1为待复原图像，分别降采样两次为B2 B3，将降采样的结果分别输入到网络中得到相应分辨率尺寸下复原结果，并将复原结果作为下一阶段的输入，从而知道后续的复原。这种多尺度的策略，类似于传统的模糊核估计中的由粗到细的策略，将复杂的问题进行分解，逐步复原，先在低分辨率下复原大尺度的信息，然后再高分辨率下复原细节信息。简化问题的同时增大了图像的感受野。
- 与文献Learning a Convolutional Neural Network for Non-uniform Motion Blur Removal对比的实验结果如图2所示。在视觉上提出的方法取得更好的视觉效果。在数据集GOPRO上的测试指标如表1所示，并对比了方法间，在不同的网络尺度数下的实验结果。

<div align=center>
    <!-- ![应用场景](./img/16cv应用场景.jpg) -->
    <img src="./img/ch5/6.jpg" width="700"/>
</div>

### 3.7 基于Gan的图像去模糊算法

- Gan为对抗生成网络，首次在文献Generative Adversarial Nets中被提出，应用于图像生成。随着Gan的发展逐步应用于图像复原领域。该文献提出将Gan应用于图像去模糊问题上。实现了一种基于深度学习的端到端的图像去模糊。提出的Gan的生成器网络模型如图3所示。生成器由两个步长为1/2的卷积网络、9个ResBlock和两个反卷积网络组成。每个ResBlock包括卷积层、instance normalization层和ReLU激活层。


<div align=center>
    <!-- ![应用场景](./img/16cv应用场景.jpg) -->
    <img src="./img/ch5/7.jpg" width="700"/>
</div>

<div align=center>
    <!-- ![应用场景](./img/16cv应用场景.jpg) -->
    <img src="./img/ch5/8.jpg" width="700"/>
</div>

上图为 生成器网络结构图和DeblurGan网络结构示意图





## 4. 任务实施
- 通过python实现上述算法，体会算法，反思改进的思路，然后通过利用深度学习的算法来尝试增强图像。
### 4.1 实施思路

- 根据知识点中提及到的数学公式，将图像增强算法的函数复现，然后利用已有图片，进行图像增强。

### 4.2 实施步骤
#### 步骤1：
- 导入用到的相关模块:
```
%matplotlib inline

import cv2
import numpy as np
from matplotlib import pyplot as plt
```


#### 步骤2：
- 显示原图:
```
#  opencv 的接口使用BGR模式，而 matplotlib.pyplot 接口使用的是RGB模式
img = cv2.imread("img1.jpg", 1)

b, g, r = cv2.split(img)
srcImage_new = cv2.merge([r, g, b])
plt.imshow(srcImage_new)
```


#### 步骤3：
```
# 彩色图像均衡化,需要分解通道 对每一个通道均衡化
(b, g, r) = cv2.split(img)
bH = cv2.equalizeHist(b)
gH = cv2.equalizeHist(g)
rH = cv2.equalizeHist(r)
# 合并每一个通道
result = cv2.merge((rH, gH, bH))
# cv2.imshow("dst", result)

plt.imshow(result)

```

#### 步骤4：
```
# Gamma图像增强
def adjust_gamma(src,gamma=2.0):
    scale = float(np.iinfo(src.dtype).max - np.iinfo(src.dtype).min)
    dst = ((src.astype(np.float32) / scale) ** gamma) * scale
    dst = np.clip(dst,0,255).astype(np.uint8)
    return dst
g_result = adjust_gamma(srcImage_new)
plt.imshow(g_result)
```

#### 步骤5：
```
# log对数图像增强
def log_enhance(src):
   
    scale = float(np.iinfo(src.dtype).max - np.iinfo(src.dtype).min)
    dst = np.log2(src.astype(np.float32) / scale + 1) * scale
    dst = np.clip(dst,0,255).astype(np.uint8)
    return dst
l_result = log_enhance(srcImage_new)
plt.imshow(l_result)
```

## 5.任务拓展
### 5.1 对彩色图像进行图像增强和对灰度图像进行图像增强的区别？

- 相信同学们都有留意到，我们课程中提供的图片处理都是采用对彩色图片进行处理，也是更加具有现实意义。
- 那么，因为通常我们的彩色图片是有R，G，B三个通道，就是之前课程中提及的，有三原色组成我们每个像素的真实色彩。如果要处理全彩色图像，则需要对彩色的每个通道分别处理，然后叠加在一起。下面以中值滤波为例，对彩色图像进行处理。

### 5.1 伪彩色？

- 将彩色图像转换为灰度图像是一个不可逆的过程，灰度图像也不可能变换为原来的彩色图像。而某些场合需要将灰度图像转变为彩色图像；伪彩色处理主要是把黑白的灰度图像或者多波段图像转换为彩色图像的技术过程。其目的是提高图像内容的可辨识度。

- 伪彩色图像的含义是，每个像素的颜色不是由每个基色分量的数值直接决定，而是把像素值当作彩色查找表(事先做好的)的表项入口地址，去查找一个显示图像时使用的R，G，B强度值，用查找出的R，G，B强度值产生的彩色称为伪彩色。









## 6. 任务实训
### 6.1 实训目的
- 掌握调用百度 api
- 加深对图像增强的理解
- 拓展图像增强的应用知识

### 6.2 实训内容

- 我们已经成功一些传统的图像处理方法对图片进行增强，而百度 AI 开放平台还提供的基于深度学习的图像增强算法提供我们调用。

### 6.3 示例代码

```
%matplotlib inline
import cv2
import numpy as np

from matplotlib import pyplot as plt

import sys
import json
import base64

import ssl
## make it work in both python2 both python3
IS_PY3 = sys.version_info.major == 3
if IS_PY3:
    from urllib.request import urlopen
    from urllib.request import Request
    from urllib.error import URLError
    from urllib.parse import urlencode
    from urllib.parse import quote_plus
else:
    import urllib2
    from urllib import quote_plus
    from urllib2 import urlopen
    from urllib2 import Request
    from urllib2 import URLError
    from urllib import urlencode


## 跳过 HTTPS 身份验证
ssl._create_default_https_context = ssl._create_unverified_context
API_KEY = '你的API_KEY'
SECRET_KEY = '你的SECRET_KEY'
IMG_ENHANCE = "https://aip.baidubce.com/rest/2.0/image-process/v1/contrast_enhance"
""" 开始 TOKEN """
TOKEN_URL = 'https://aip.baidubce.com/oauth/2.0/token'


""" 请求认证 token
"""
def fetch_token():
    params = {'grant_type': 'client_credentials',
        'client_id': API_KEY,
        'client_secret': SECRET_KEY}
    post_data = urlencode(params)
    if (IS_PY3):
        post_data = post_data.encode('utf-8')
    req = Request(TOKEN_URL, post_data)
    try:
        f = urlopen(req, timeout=5)
        result_str = f.read()
    except URLError as err:
        print(err)
    if (IS_PY3):
        result_str = result_str.decode()
    result = json.loads(result_str)
    if ('access_token' in result.keys() and 'scope' in result.keys()):
        if not 'brain_all_scope' in result['scope'].split(' '):
            print ('please ensure has check the ability')
            exit()
        return result['access_token']
    else:
        print ('please overwrite the correct API_KEY and SECRET_KEY')
        exit()


""" 读取图片函数
"""

def read_file(image_path):
    f = None
    try:
        f = open(image_path, 'rb') #用二进制打开图片
        return f.read()
    except:
        print('read image file fail')
        return None
    finally:
        if f:
            f.close()


"""
call remote http server
"""
def request(url, data):
    req = Request(url, data.encode('utf-8'))
    has_error = False
    try:
        f = urlopen(req)
        result_str = f.read()
        if (IS_PY3):
            result_str = result_str.decode()
        return result_str
    except URLError as err:
        print(err)


if __name__ == '__main__':
    ## get access token
    token = fetch_token()
    ## concat url
    url = IMG_ENHANCE + "?access_token=" + token
    
    file_content = read_file('./img2.jpg')
    response = request(url, urlencode(
    {
        'image': base64.b64encode(file_content),
        'image_type': 'BASE64',
    }))
    data = json.loads(response)
#     print(data)
    sourceImg = cv2.imread('img2.jpg')
    srcImage_new = cv2.cvtColor(sourceImg, cv2.COLOR_BGR2RGB)
    plt.imshow(srcImage_new)
    plt.show()


image_data = base64.b64decode(data['image'])
with open('2.jpg', 'wb') as f:
    f.write(image_data)
sourceImg = cv2.imread('2.jpg')
srcImage_new = cv2.cvtColor(sourceImg, cv2.COLOR_BGR2RGB)
plt.imshow(srcImage_new)
plt.show()



```

