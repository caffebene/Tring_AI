[toc]
# 任务1 深度学习概述与环境搭建
## 1 任务目标

- 了解深度学习的研究背景
- 了解深度学习的应用场景
- 实验环境的搭建

## 2 任务描述
- 绪论将从什么是深度学习、深度学习的发展历程、深度学习的相关要素几个方面来讲述。
- 了解任务使用的主要框架，动手搭建实验环境

## 3 知识准备
### 3.1 什么是深度学习
深度学习（deep learning）是机器学习的分支，是一种以人工神经网络为架构，对数据进行表征学习的算法。

深度学习是机器学习中一种基于对数据进行表征学习的算法。观测值（例如一幅图像）可以使用多种方式来表示，如每个像素强度值的向量，或者更抽象地表示成一系列边、特定形状的区域等。而使用某些特定的表示方法更容易从实例中学习任务（例如，人脸识别或面部表情识别）。深度学习的好处是用非监督式或半监督式的特征学习和分层特征提取高效算法来替代手工获取特征。

表征学习的目标是寻求更好的表示方法并创建更好的模型来从大规模未标记数据中学习这些表示方法。表示方法来自神经科学，并松散地创建在类似神经系统中的信息处理和对通信模式的理解上，如神经编码，试图定义拉动神经元的反应之间的关系以及大脑中的神经元的电活动之间的关系。

### 3.1 深度学习的发展历程
 
#### 3.1.1 深度学习的起源阶段

1943年，心里学家麦卡洛克和数学逻辑学家皮兹发表论文《神经活动中内在思想的逻辑演算》，提出了MP模型。MP模型是模仿神经元的结构和工作原理，构成出的一个基于神经网络的数学模型，本质上是一种“模拟人类大脑”的神经元模型。MP模型作为人工神经网络的起源，开创了人工神经网络的新时代，也奠定了神经网络模型的基础。

1949年，加拿大著名心理学家唐纳德·赫布在《行为的组织》中提出了一种基于无监督学习的规则——海布学习规则(Hebb Rule)。海布规则模仿人类认知世界的过程建立一种“网络模型”，该网络模型针对训练集进行大量的训练并提取训练集的统计特征，然后按照样本的相似程度进行分类，把相互之间联系密切的样本分为一类，这样就把样本分成了若干类。海布学习规则与“条件反射”机理一致，为以后的神经网络学习算法奠定了基础，具有重大的历史意义。

20世纪50年代末，在MP模型和海布学习规则的研究基础上，美国科学家罗森布拉特发现了一种类似于人类学习过程的学习算法——感知机学习。并于1958年，正式提出了由两层神经元组成的神经网络，称之为“感知器”。感知器本质上是一种线性模型，可以对输入的训练集数据进行二分类，且能够在训练集中自动更新权值。感知器的提出吸引了大量科学家对人工神经网络研究的兴趣，对神经网络的发展具有里程碑式的意义。

但随着研究的深入，在1969年，“AI之父”马文·明斯基和LOGO语言的创始人西蒙·派珀特共同编写了一本书籍《感知器》，在书中他们证明了单层感知器无法解决线性不可分问题（例如：异或问题）。由于这个致命的缺陷以及没有及时推广感知器到多层神经网络中，在20世纪70年代，人工神经网络进入了第一个寒冬期，人们对神经网络的研究也停滞了将近20年。

![](https://ae01.alicdn.com/kf/H765d4b30d21e48069c30ceccca9333daL.png)

“AI之父”马文·明斯基

#### 3.1.2 深度学习的发展阶段

1982年，著名物理学家约翰·霍普菲尔德发明了Hopfield神经网络。Hopfield神经网络是一种结合存储系统和二元系统的循环神经网络。Hopfield网络也可以模拟人类的记忆，根据激活函数的选取不同，有连续型和离散型两种类型，分别用于优化计算和联想记忆。但由于容易陷入局部最小值的缺陷，该算法并未在当时引起很大的轰动。

直到1986年，深度学习之父杰弗里·辛顿提出了一种适用于多层感知器的反向传播算法——BP算法。BP算法在传统神经网络正向传播的基础上，增加了误差的反向传播过程。反向传播过程不断地调整神经元之间的权值和阈值，直到输出的误差达到减小到允许的范围之内，或达到预先设定的训练次数为止。BP算法完美的解决了非线性分类问题，让人工神经网络再次的引起了人们广泛的关注。

![](https://ae01.alicdn.com/kf/H39fece4d723e4cb1b067733a546897921.png)

深度学习之父杰弗里·辛顿

但是由于八十年代计算机的硬件水平有限，如：运算能力跟不上，这就导致当神经网络的规模增大时，再使用BP算法会出现“梯度消失”的问题。这使得BP算法的发展受到了很大的限制。再加上90年代中期，以SVM为代表的其它浅层机器学习算法被提出，并在分类、回归问题上均取得了很好的效果，其原理又明显不同于神经网络模型，所以人工神经网络的发展再次进入了瓶颈期。

#### 3.1.3 深度学习的爆发阶段

2006年，杰弗里·辛顿以及他的学生鲁斯兰·萨拉赫丁诺夫正式提出了深度学习的概念。他们在世界顶级学术期刊《科学》发表的一篇文章中详细的给出了“梯度消失”问题的解决方案——通过无监督的学习方法逐层训练算法，再使用有监督的反向传播算法进行调优。该深度学习方法的提出，立即在学术圈引起了巨大的反响，以斯坦福大学、多伦多大学为代表的众多世界知名高校纷纷投入巨大的人力、财力进行深度学习领域的相关研究。而后又在迅速蔓延到工业界中。

2012年，在著名的ImageNet图像识别大赛中，杰弗里·辛顿领导的小组采用深度学习模型AlexNet一举夺冠。AlexNet采用ReLU激活函数，从根本上解决了梯度消失问题，并采用GPU极大的提高了模型的运算速度。同年，由斯坦福大学著名的吴恩达教授和世界顶尖计算机专家Jeff Dean共同主导的深度神经网络——DNN技术在图像识别领域取得了惊人的成绩，在ImageNet评测中成功的把错误率从26％降低到了15％。深度学习算法在世界大赛的脱颖而出，也再一次吸引了学术界和工业界对于深度学习领域的关注。

随着深度学习技术的不断进步以及数据处理能力的不断提升，2014年，Facebook基于深度学习技术的DeepFace项目，在人脸识别方面的准确率已经能达到97%以上，跟人类识别的准确率几乎没有差别。这样的结果也再一次证明了深度学习算法在图像识别方面的一骑绝尘。

2016年，随着谷歌公司基于深度学习开发的AlphaGo以4:1的比分战胜了国际顶尖围棋高手李世石，深度学习的热度一时无两。后来，AlphaGo又接连和众多世界级围棋高手过招，均取得了完胜。这也证明了在围棋界，基于深度学习技术的机器人已经超越了人类。

![](https://ae01.alicdn.com/kf/H4144bc97ffe049e6974841562a3e9b95I.png)

AlphaGo大战李世石

2017年，基于强化学习算法的AlphaGo升级版AlphaGo Zero横空出世。其采用“从零开始”、“无师自通”的学习模式，以100:0的比分轻而易举打败了之前的AlphaGo。除了围棋，它还精通国际象棋等其它棋类游戏，可以说是真正的棋类“天才”。此外在这一年，深度学习的相关算法在医疗、金融、艺术、无人驾驶等多个领域均取得了显著的成果。所以，也有专家把2017年看作是深度学习甚至是人工智能发展最为突飞猛进的一年。

所以在深度学习的浪潮之下，不管是AI的相关从业者还是其他各行各业的工作者，都应该以开放、学习的心态关注深度学习、人工智能的热点动态。人工智能正在悄无声息的改变着我们的生活！

### 3.2 深度学习的相关要素

近年来深度学习发展神速，在语音、图像、自然语言处理等技术上取得了前所未有的突破。本轮人工智能的快速发展离不开三大关键要素：算力、数据和算法。

首先，大规模、高性能的云端计算硬件集群是人工智能发展的强劲引擎。目前深度学习算法模型结构复杂，规模大、参数多；模型的开发门槛很高。面对这些挑战，高性能的硬件，如GPU/FPGA/ASIC等，尤其是面向人工智能应用的专用芯片的发展，让机器学习的训练速度数倍提升。

第二，数据是推动人工智能发展的燃料，机器学习技术需要大量标注数据来作训练模型，在海量数据样本的基础上挖掘信息，得到有用的知识，从而做出决策。移动互联网、IoT物联网的发展，不止让手机这样的移动设备接入互联网，每一个音箱、每一个电视、每一个冰箱都可以接入云，获得人工智能的能力和服务。用户通过这些设备感受到AI带来的便利，实际上背后是云上提供的服务。云是AI的container，如果将AI比作电的话，云就是核电站，为各行各业提供源源不断的智能核动力。

第三，是不断推陈出新的人工智能算法突破，从卷积神经网络（Convolutional neural network，简称CNN）到递归神经网络（Recurrent neural network，简称RNN），从生成式对抗网络（Generative adversarial networks，简称GANs）到迁移学习（Transfer learning）。每一次新算法的提出或改进，带来了应用效果的大幅提升。人工智能技术在语音、图像、自然语言等众多领域的使用，推动这次人工智能大潮的持续发展。

### 3.3 TensorFlow框架简介

TensorFlow是谷歌的开源机器学习框架，采用数据流图（data flow graphs），用于数值计算的开源软件库。节点（Nodes）在图中表示数学操作，图中的线（edges）则表示在节点间相互联系的多维数据数组，即Tensor（张量），而Flow（流）意味着基于数据流图的计算，TensorFlow为张量从流图的一端流动到另一端计算过程。TensorFlow不只局限于神经网络，其数据流式图支持非常自由的算法表达，当然也可以轻松实现深度学习以外的机器学习算法。事实上，只要可以将计算表示成计算图的形式，就可以使用TensorFlow。TensorFlow可被用于语音识别或图像识别等多项机器深度学习领域，TensorFlow一大亮点是支持异构设备分布式计算，它能够在各个平台上自动运行模型，从手机、单个CPU / GPU到成百上千GPU卡组成的分布式系统。

## 4 任务实施

### 4.1 实施思路
本次任务需要动手的部分主要是实验环境的搭建，实验环境主要是集成了TensorFlow框架的Jupyter NoteBook，它是一个python的集成编译环境。任务需要做的就是通过下载Anaconda来安装Jupyter Notebook，然后再安装TensorFlow。

### 4.2 实施步骤
1. 下载并安装Anaconda
2. 启动Jupyter Notebook
3. 利用Anaconda环境安装TensorFlow


## 5 任务拓展
### 可视化工具tensorboard
对大部分人而言，深度神经网络就像一个黑盒子，其内部的组织、结构、以及其训练过程很难理清楚，这给深度神经网络原理的理解和工程化带来了很大的挑战。为了解决这个问题，tensorboard应运而生。Tensorboard是tensorflow内置的一个可视化工具，它通过将tensorflow程序输出的日志文件的信息可视化使得tensorflow程序的理解、调试和优化更加简单高效。Tensorboard的可视化依赖于tensorflow程序运行输出的日志文件，因而tensorboard和tensorflow程序在不同的进程中运行。


![](https://puui.qpic.cn/fans_admin/0/3_1838438656_1566626485134/0)


![](https://puui.qpic.cn/fans_admin/0/3_1840954026_1566626485356/0)

tensorboard可视化效果

## 6 任务实训

### 6.1 实训目的

本次实训是环境搭建，大家可以在自己的计算机里面搭建好实验环境，从而在课后练习巩固所学内容。

### 6.2 实训内容

#### 下载Anaconda
- 在Anaconda官网[https://www.anaconda.com/distribution/](https://www.anaconda.com/distribution/)
下载Linux版本的Anaconda，本教程下载的是Python 3.7 版本，点击Download即可下载到 ~/Downloads/ 目录下

![](https://puui.qpic.cn/fans_admin/0/3_1840954026_1566626366061/0)


- 安装Anaconda

    - 在下载完成后，打开一个终端，输入命令：
cd Downloads

    - 在sudo权限下运行安装脚本，输入命令：
sudo ./Anaconda3-2019.07-Linux-x86_64.sh

    - 安装期间需要enter确认安装信息，
并需要输入Yes确认安装位置
等待安装完成即可

![](https://puui.qpic.cn/fans_admin/0/3_1800723602_1566626366047/0)
        

> 意外的情况： 运行脚本时找不到命令

    解决方案：
    =>打开文件系统Files 
    =>找到该脚本
    =>右键点击最下边的properties
    =>在弹出的窗口点击Permission选项卡
    =>勾选Allow executing files as program
    =>然后重新按步骤执行即可


- [x] Anaconda安装成功后在终端输入命令jupyter notebook，
即会自动转到浏览器的jupyter页面。
    
![](https://puui.qpic.cn/fans_admin/0/3_1838438656_1566626366413/0)
    

#### 利用Conda创建TensorFlow环境并安装
     
-   先安装ipykernel，在终端输入：
	
```
conda install ipykernel
```


-   创建虚拟环境：
	
```
conda create -n tf  python=3.7 ipykernel
```


-   激活虚拟环境：
	
```
source activate tf
```


-   将环境写入notebook的kernel中：
	
```
python -m ipykernel install --user --name tf --display-name “tf"
```




> 意外的情况：
安装ipykernel时报错——
EnvironmentNotWritableError: The current user does not have write permissions to the target environment.

    原因是当前用户权限不足，解决方案：
    输入命令： sudo chmod -R 777 /home/<user>/anaconda3

    <user>为当前用户名

    然后重新按步骤执行即可

#### 安装TensorFlow
- 在终端执行命令：

```
conda install tensorflow
```

	
- 验证安装：
=>输入jupyter notebook转到jupyter页面
在jupyter页面的右边有一个New的按钮

- =>点击New选择之前创建好的TensorFlow环境tf，
进入Python编程界面，在第一行敲入代码：

```
import tensorflow as tf
```


 - =>选中第一行，点击Run按钮，
如无报错，则证明安装成功。

![](https://puui.qpic.cn/fans_admin/0/3_1809782443_1566626366155/0)
