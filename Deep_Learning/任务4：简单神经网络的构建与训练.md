[TOC]
# 任务4：简单神经网络的构建与训练

## 1 任务目标

1. 学习并理解神经网络模型

2. 了解如何训练神经网络

3. 搭建一个简单的神经网络

4. 利用MNIST数据集训练并进行预测


## 2 任务描述

神经网络是深度学习当中最为基础，又最为重要的一个模型。上个任务所介绍的感知器模型，即神经网络的基本单元——神经元，神经网络就是基于感知器进行扩充从而形成一个网络，因此神经网络又叫做多层感知器。在本任务中，将会详细介绍神经网络及其搭建和训练。

## 3 知识准备

### 3.1 什么是神经网络

![](https://ae01.alicdn.com/kf/Hdba8218dda5344da81804478375901334.png)

神经元是神经网络的基本组成单元（本质上就是感知器）；神经元排成一列，每一列之间连接起来，构成神经网络。

上图展示了一个**全连接(full connected, FC)神经网络**，通过观察上面的图，我们可以发现它的连接规则包括：

- 神经元按照层来布局。最左边的层叫做输入层，负责接收输入数据；最右边的层叫输出层，我们可以从这层获取神经网络输出数据。输入层和输出层之间的层叫做隐藏层，因为它们对于外部来说是不可见的。
- 同一层的神经元之间没有连接。
- 第N层的每个神经元和第N-1层的所有神经元相连(这就是全连接的含义，最简单的连接方式)，第N-1层神经元的输出就是第N层神经元的输入。
- 每个连接都有一个**权值**。
- 此外，被连接的每一个神经元还有未标出的**偏置以及激活函数**

上面这些规则定义了全连接神经网络的结构。事实上还存在很多其它结构的神经网络，比如卷积神经网络(CNN)、循环神经网络(RNN)，他们都具有不同的连接规则。

### 3.2 神经网络的训练

同感知器的训练一样，神经网络也是需要训练，对数据进行学习，才能发挥作用。也就是如何将各个权值和偏置调到最优值，使网络最终具备一定能力的问题。

在讲训练的算法之前，有些知识是需要事先知道的。

- **监督学习**——给定输入以及输出，使模型学习后具备由输入得出输出的能力；**无监督学习**——让模型通过某种规则来得出数据集中的某些规律，可以理解为只给定输入。
- **目标函数（也称损失函数）**——在监督学习当中，衡量模型当前的输出与正确的输出之差的函数，显然它是关于权值和偏置的函数。

本任务中所讲到的训练是监督学习，给定一系列输入与输出后，我们将输入送进神经网络后得到其输出，将此输出与正确的结果作对比，设置一个目标函数。

好了，我们现在有了目标函数，它表示神经网络的输出与正确的结果到底还差多少。那么我们求出这个目标函数的最小值，此时对应的权值和偏置不就是我们想要的吗？

是的。那么问题就转化为求一个函数的最小值的问题。问题又来了，计算机会求函数的最小值吗？答案是否定的。但是计算机能够通过计算不断地逼近函数的最小值。这就要提到接下来的梯度下降法。

#### 3.2.1 梯度下降法（Gradient Descent）

我们都知道，对于一个可导的函数，求它的最小值，就需要对其求导数，求出其极小值。如果是多元函数，函数沿梯度的方向增长最快，反之就往负梯度的方向减小的最快。于是，计算机想要求一个函数的最小值，就可以先求梯度，然后将自变量往负梯度的方向一点点地下降；再求梯度，自变量再一点点地下降，直至找到函数的最小值。这就是梯度下降法。

这种方法在代码里面一般通过一个叫“优化器（optimizer）”的东西来实现。

对于神经网络的训练来说，自变量往目标函数的负梯度下降，这个自变量在这里显然就是指权值和偏置，权值和偏置在梯度下降时不断地更新，从而达到最优。

### 3.3 MNIST数据集
MNIST是深度学习的经典入门demo，它是由6万张训练图片和1万张测试图片构成的，每张图片都是28\*28大小（如下图），而且都是黑白色构成（这里的黑色是一个0-1的浮点数，黑色越深表示数值越靠近1），这些图片是采集的不同的人手写从0到9的数字。TensorFlow将这个数据集和相关操作封装到了库中。

 下图就是1张MNIST图片。这些图片并不是传统意义上的png或者jpg格式的图片，因为png或者jpg的图片格式，会带有很多干扰信息（如：数据块，图片头，图片尾，长度等等），这些图片会被处理成很简易的二维数组。
 
 在任务实施中，我们将会以MNIST数据集来训练一个简单的神经网络。
 
![c8e0ed20615e1c318f655bfe46fa35a0.png](https://s2.ax1x.com/2019/08/14/miX8sA.png)



## 4 任务实施


### 4.1 实施思路

1.导入数据集

2.创建占位符来接收输入输出

3.创建权重和变量

4.用矩阵乘法构建全连接神经网络

5.定义目标函数及其优化器

6.训练模型

7.评估模型准确率

### 4.2 实施步骤

#### 4.2.1 导入数据集

以下代码会下载并读取MNIST数据集，下载好的数据集包括训练集的60000张28*28的手写数字图片，以及测试集的10000张同样的图片，每一张图片都包含一个“one-hot”标签，它是个一维数组，只有一个元素为1，其余为0，因此它有标识作用。

```
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
```

#### 4.2.2 创建占位符

占位符用来接收输入和输出，规定输入输出的格式和规模。

```
#放置占位符，用于在计算时接收输入值
x = tf.placeholder("float", [None, 784])
#放置占位符，用于接收正确值
y_ = tf.placeholder("float", [None,10])

```

#### 4.2.3 创建权重和偏置

将28x28像素的手写数字图片传入的话，那么就有784个输入，再对应10个可能的输出，因此权重有784x10个权重，10个偏置
```
#创建两个变量，分别用来存放权重值W和偏置值b
W = tf.Variable(tf.zeros([784, 10]))
b = tf.Variable(tf.zeros([10]))
```
#### 4.2.4 用矩阵乘法构建全连接神经网络

![](https://ae01.alicdn.com/kf/H9684aa4a42b340258bb79bb964882abcv.png)

因为全连接神经网络中每层的神经元与下一层的神经元分别都有连接，因此其权重可以用矩阵来表示（如上图），而连接恰巧可以用矩阵乘法来实现。

选用的激活函数是softmax函数，它能将输入转换为概率。


```
#使用Tensorflow提供的回归模型softmax，y代表输出
y = tf.nn.softmax(tf.matmul(x, W) + b)
```
#### 4.2.5 定义目标函数及其优化器

选用的目标函数叫做交叉熵函数，详细可参见任务拓展。而选用的优化器是梯度下降优化器，用以实现前文所提到的梯度下降法。

```
#计算交叉墒
cross_entropy = -tf.reduce_sum(y_ * tf.log(y))
 
#使用梯度下降算法以0.01的学习率最小化交叉墒
train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)
```
#### 4.2.6 训练模型

先要进行初始化操作，然后启动会话去训练模型

```
#初始化之前创建的变量的操作
init = tf.initialize_all_variables()
 
#启动初始化
sess = tf.Session()
sess.run(init)
 
#开始训练模型，循环1000次，每次都会随机抓取训练数据中的100条数据，然后作为参数替换之前的占位符来运行
for i in range(200):
    batch_xs, batch_ys = mnist.train.next_batch(50)
    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
```

#### 4.2.7 评估模型

训练完模型后，即评估模型的训练效果，用该模型去预测测试集，然后计算其准确率。


```
#评估模型，tf.argmax能给出某个tensor对象在某一维上数据最大值的索引。因为标签是由0,1组成了one-hot vector，返回的索引就是数值为1的位置
correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1)) 
 
#计算正确预测项的比例，因为tf.equal返回的是布尔值，使用tf.cast可以把布尔值转换成浮点数，tf.reduce_mean是求平均值
accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))
 
#在session中启动accuracy，输入是MNIST中的测试集
print (sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))

```

## 5 任务拓展

### 交叉熵函数

一些常用的代价函数在用作训练时，每一次训练对于 w 和 b 的更新非常慢，为了克服这个缺点，引入了交叉熵代价函数：

```math
C =-{1\over {n}}\sum_{i=1}^ny_ilog(a_i)
```
y为期望的正确输出，a为神经元的实际输出，与方差代价函数一样，交叉熵代价函数同样有两个性质：
- 非负性。（所以我们的目标就是最小化代价函数）
- 当真实输出a与期望输出y接近的时候，代价函数接近于0(比如y=0，a～0；y=1，a~1时，代价函数都接近0)。

无论是对权重还是偏置，它的导数都仅受(a-y)的影响，即仅受误差影响，所以当误差大的时候，权重更新就快，当误差小的时候，权重的更新就慢。这是一个很好的性质。



## 6 任务实训

### 6.1 实训目的

巩固本次任务

### 6.2 实训内容

尝试自己训练模型，存储模型并用以预测

#### 示例代码


```
import sys,os
sys.path.append(os.pardir)
import numpy as np
from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf
import matplotlib.pyplot as plt

def predict():
    meta_path = 'ckpt/mnist.ckpt.meta'
    model_path = 'ckpt/mnist.ckpt'
    sess = tf.InteractiveSession ()
    saver = tf.train.import_meta_graph (meta_path)
    saver.restore (sess, model_path)
    graph = tf.get_default_graph ()
    W = graph.get_tensor_by_name ("w:0")
    b = graph.get_tensor_by_name ("b:0")
    x = tf.placeholder (tf.float32, [None, 784])
    y = tf.nn.softmax (tf.matmul (x, W) + b)
    keep_prob = tf.placeholder (tf.float32)
    batch_xs, batch_ys=mnist.train.next_batch (100)
    
    for i in range(5):
        one_img = batch_xs[i].reshape ((1, 784))
        one_num = batch_ys[i].reshape ((1, 10))
        temp = sess.run (y, feed_dict={x: one_img, keep_prob: 1.0})
        b = sess.run (tf.argmax (temp, 1))
        a = sess.run (tf.arg_max (one_num, 1))
        print(temp)
        print(one_num)
        if b == a:
            print ("success! the num is :", (b[0]))
            plt.imshow(batch_xs[i].reshape(-1,28),cmap='gray_r')
            plt.axis('off')
            plt.show()
        else:
            print ("mistakes predict.")
            plt.imshow(batch_xs[i].reshape(-1,28),cmap='gray_r')
            plt.axis('off')
            plt.show()

def trainNet():
    tf.reset_default_graph()
    x = tf.placeholder (tf.float32, [None, 784])
    W = tf.Variable (tf.zeros ([784, 10]), name="w")
    b = tf.Variable (tf.zeros ([10]),name="b")
    y = tf.nn.softmax (tf.matmul (x, W) + b)
    y_ = tf.placeholder (tf.float32, [None, 10])
    keep_prob = tf.placeholder (tf.float32)
    # 定义测试的准确率
    correct_prediction = tf.equal (tf.argmax (y, 1), tf.argmax (y_, 1))
    accuracy = tf.reduce_mean (tf.cast (correct_prediction, tf.float32))
    
    saver = tf.train.Saver (max_to_keep=1)
    max_acc = 0
    train_accuracy = 0
    #交叉熵
    cross_entropy = tf.reduce_mean (-tf.reduce_sum (y_ * tf.log (y)))
    # cross_error=cross_entropy_error_batch(y,y_)
    train_step = tf.train.GradientDescentOptimizer (0.01).minimize (cross_entropy)
    sess = tf.InteractiveSession ()
    tf.global_variables_initializer ().run ()

    for i in range (1000):
        batch_xs, batch_ys = mnist.train.next_batch (100)
        sess.run (train_step, feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 1.0})
        if i % 100 == 0:
            train_accuracy = accuracy.eval (feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 1.0})
            print ("step %d, training accuracy %g" % (i, train_accuracy))
        if train_accuracy > max_acc:
            max_acc = train_accuracy
            saver.save (sess, 'ckpt/mnist.ckpt')

if __name__ == '__main__':
    mnist = input_data.read_data_sets ("MNIST_data/", one_hot=True)
    choice=0
    while choice == 0:
        print ("------------------------tensorflow--------------------------")
        print ("\t\t\t1\ttrain model..")
        print("\t\t\t2\tpredict model")
        choice = input ("please input your choice！")
        print(choice)
        if choice == "1":
            print("start train...")
            trainNet()
        if choice=="2":
            predict()
```

#### 运行结果
输入1可训练模型

![](https://pic.superbed.cn/item/5d60cccd451253d17830ea3b.png)

输入2可随机选取5张样本进行测试

![](https://pic.superbed.cn/item/5d60cccd451253d17830ea3d.png)