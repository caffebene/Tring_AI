[TOC]
# 任务6：卷积神经网络实战

## 1 任务目标

1. 学习并理解卷积神经网络的优点

2. 搭建一个完整的CNN

3. 用MNIST数据集验证CNN



## 2 任务描述

上个任务当中介绍了 CNN 当中各项基本要素，以及如何调用 TensorFlow 的 API 来搭建 CNN，任务实训当中还要求同学们对比 CNN 和传统的神经网络，找出它们的异同。那么在本次任务中，将揭晓这些异同点，并用 CNN 来对 MNIST 数据集再作一次验证。


## 3 知识准备


### 3.1 CNN 与传统神经网络的对比

其实现在回过头来看，CNN跟我们之前学习的神经网络，也没有很大的差别。
传统的神经网络，其实就是多个全连接层叠加起来。
CNN，无非就是把全连接层改成了卷积层和池化层，就是把传统的由一个个神经元组成的层，变成了由卷积核组成的层。

那么，为什么要这样变？有什么好处？
具体说来有两点：

#### 1.参数共享机制（parameters sharing）

我们对比一下传统神经网络的层和由卷积核构成的卷积层：
假设我们的图像是8×8大小，也就是64个像素，假设我们用一个有9个单元的全连接层：

![](https://ae01.alicdn.com/kf/H4fbee8dbab294500aede771e5c71fdabt.jpg)

那这一层我们需要多少个参数呢？需要 64×9 = 576个参数（先不考虑偏置项b）。因为每一个链接都需要一个权重w。

那我们看看 同样有9个单元的卷积核是怎么样的：

![](https://ae01.alicdn.com/kf/Hec5d6217fc03478aa377d93625c91d3eX.jpg)

其实不用看就知道，有几个单元就几个参数，所以总共就9个参数！

因为，对于不同的区域，我们都共享同一个filter，因此就共享这同一组参数。
这也是有道理的，通过前面的讲解我们知道，filter是用来检测特征的，那一个特征一般情况下很可能在不止一个地方出现，比如“竖直边界”，就可能在一幅图中多出出现，那么 我们共享同一个filter不仅是合理的，而且是应该这么做的。

由此可见，参数共享机制，让我们的网络的参数数量大大地减少。这样，我们可以用较少的参数，训练出更加好的模型，典型的事半功倍，而且可以有效地 避免过拟合。
同样，由于filter的参数共享，即使图片进行了一定的平移操作，我们照样可以识别出特征，这叫做 “平移不变性”。因此，模型就更加稳健了。


#### 2.连接的稀疏性（sparsity of connections）

由卷积的操作可知，输出图像中的任何一个单元，只跟输入图像的一部分有关系：

![](https://ae01.alicdn.com/kf/H0a87ed8c2a6c410e87e16ae5f9a049a4R.jpg)

而传统神经网络中，由于都是全连接，所以输出的任何一个单元，都要受输入的所有的单元的影响。这样无形中会对图像的识别效果大打折扣。比较，每一个区域都有自己的专属特征，我们不希望它受到其他区域的影响。

正是由于上面这两大优势，使得CNN超越了传统的NN，开启了神经网络的新时代。

## 4 任务实施

### 4.1 实施思路
- 定义输入和输出
- 定义权重和偏置的初始化函数
- 根据输入构建卷积层，定义好滤波器
- 构建池化层、全连接层
- 定义及最小化损失函数（交叉熵函数）
- 定义准确率的计算
- 训练模型
- 测试模型

### 4.2 实施步骤
#### 定义输入与输出
- x = tf.placeholder(tf.float32, [None, 784])#特征
- y_ = tf.placeholder(tf.float32, [None, 10])#标签	

- x为784位的占位符，接受784个像素点的输入
- y_为10位占位符，接受0~9十个标签的输入

- 之所以使用占位符是因为当计算图还没有在会话中运行时，图中的节点是没有数据的，这个时候就需要占位符把数据的位置先占好。

#### 权重和偏置的初始化函数
- tf.Variable(initial) 生成一个变量 tensor，参数 initial 是初始化值。
- shape 指定了生成变量的维度，initial 由truncated_normal 方法生成的正态分布的值。
- 给权重制造一些随机的噪声来打破完全对称，比如截断的正态分布噪声，标准差设为0.1。
- 而偏置初始化为常量即可，以打破对称性及避免0 梯度，提升模型训练的效率。


```
def weight_varible(shape):
    initial = tf.truncated_normal(shape,stddev = 0.1)#stddev表示标准差
    return tf.Variable(initial)

def bias_variable(shape):  
    initial = tf.constant(0.1, shape=shape)  
    return tf.Variable(initial)
```

#### 构建卷积层
- TensorFlow已提供了卷积的实现 tf.nn.conv2d()
- 参数列表： x为输入矩阵，W为滤波器，步长strides为卷积时在图像每一维每一次移动的步长，填充模式padding为’SAME’代表在输入周围矩阵填充0使输出的特征矩阵与输入矩阵维度相同。
- 输入x要求具有 [图片数量, 图片高度, 图片宽度, 图像通道数] 四维的数据。
- 滤波器W要求具有 [滤波器的高度，滤波器的宽度，图像通道数，滤波器个数] 四维数据


```
def conv2d(x, W): 
	return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
```

- reshape(input,[ ])为变形函数，可以将tensor转换为各种维度，参数中 -1 表示自动设置该维度的数值，当数量不确定时使用。
- 下列代码的含义是，将输入变形为28X28的矩阵用5X5的滤波器去卷积，由于滤波器的数量为32，以及’SAME’填充，加上偏置，输出的特征矩阵也是28*28，数量也为32个
- 第二层卷积层同理
- 卷积完的结果经过激活函数relu()处理，将所有小于0的元素置零，然后再输出特征矩阵


```
x_image = tf.reshape(x,[-1,28,28,1]) # x为784位占位符
W_conv1 = weight_variable([5, 5, 1, 32])      
b_conv1 = bias_variable([32])    
h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
```

#### 构建池化层
- 在第一层卷积层后面紧跟一层池化层。
- 池化层在 2X2 的 4 个像素点中取最大值，当然也可以取平均值以及最小值，不过经过研究，最大池化能够比较好的保持原来的特征值。
- 经过池化后，原来28X28的特征矩阵将变为14X14


```
def max_pool_2x2(x):
# 因为希望整体上缩小图片尺寸，所以池化层的strides设为横竖方向以2为步长。   
    return tf.nn.max_pool(x,ksize = [1,2,2,1],strides = [1,2,2,1],padding='SAME')

# h_conv1是第一层卷积层输出的特征矩阵
h_pool1 = max_pool_2x2(h_conv1)
```

#### 构建全连接层
- 全连接层即该层每一个神经元均与前面一层或者后面一层的所有神经元连接
- 此连接方式正好用矩阵乘法来实现，即输入矩阵乘以权重矩阵 w 再加上偏置 b，再送进relu函数去处理
- 将7*7*64的特征矩阵与1024个神经元相连，得到1024个特征点，即第一层全连接层。
- 在与下一层全连接层相连之前，先连接一个dropout层，目的为了减轻过拟合，这里了解一下就可以了。
- 最后再与10个神经元的softmax全连接层相连，转化为概率，整个网络即搭建完毕


```

W_fc1 = weight_varible([7*7*64,1024])  # 全连接层隐含节点为1024个
b_fc1 = bias_variable([1024])
h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])  # 对第二个卷积层的输出tensor进行变形，将其转化为1D的向量
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1) + b_fc1)

# 为了减轻过拟合，下面使用一个dropout层
keep_prob = tf.placeholder(tf.float32)
h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)

# 将dropout层的输出连接一个softmax层，得到最后的概率输出
W_fc2 = weight_varible([1024,10])
b_fc2 = bias_variable([10])
y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)
```

#### 损失函数与准确率
- tf.reduce_mean()为求平均值函数
- tf.argmax()为求最大值下标的函数
- tf.equal()函数判断对应位置元素是否相等，返回包含true或false的一维数据
- tf.cast()函数为类型转换函数，该处将true和false转化为0和1


```
# 定义损失函数为cross entronpy，优化器使用Adam
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y_conv),reduction_indices=[1]))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)  # 学习率为1e-4

# 定义评测准确率的操作
corret_prediction = tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(corret_prediction,tf.float32))
```
#### 模型训练与测试


```
# 开始训练过程
tf.global_variables_initializer().run()
for i in range(2000):  # 进行2000次迭代训练
batch = mnist.train.next_batch(50)
    if i % 100 == 0:  # 每进行100次训练，对准确率进行一次评测。        train_accuracy = accuracy.eval(feed_dict = {x:batch[0], y_:batch[1], keep_prob:1.0})
        print("step %d,training accurancy %g"%(i, train_accuracy))
    train_step.run(feed_dict = {x:batch[0],y_:batch[1],keep_prob:0.5})
# 全部训练完成后，在最终的测试集上进行全面的测试，得到整体的分类准确率
batch_test = mnist.test.next_batch(1000)
print("test accuracy %g" % accuracy.eval(feed_dict = {x:batch_test[0], y_:batch_test[1], keep_prob:0.5}))
```

## 5 任务拓展
### 过拟合的问题与解决

模型过度拟合，在训练集（training set）上表现好，但是在测试集上效果差，也就是说在已知的数据集合中非常好，但是在添加一些新的数据进来训练效果就会差很多，造成这样的原因是考虑影响因素太多，超出自变量的维度过于多了。

![](https://p.pstatp.com/origin/dc11000298b384d7a672)

在计算的过程中，随机的“丢弃”一些节点，简单来说，h_fc1有 1024 个节点，在 droupout 之后，如果 keep_prob 是50%，那么经过 droupout 之后，可以认为参与计算的是 512 个节点。droupout 有两个优势。
- 解决过拟合的问题
- 在训练中加入概率性
 
![](https://p.pstatp.com/origin/fe660000ae53e859a8f7)

## 6 任务实训

### 6.1 实训目的

卷积神经网络实战，加深在实现上的理解。

### 6.2 实训内容

- 根据任务实施中的内容自己搭建一个卷积神经网络
- 调节各个超参数，如卷积核的数量、学习率、训练迭代次数等，体会训练后模型识别率的差异。